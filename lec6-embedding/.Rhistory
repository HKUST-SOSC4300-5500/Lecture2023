library(quanteda)
library(Rtsne)
library(data.table) # this package help you to read large files quicker
reviews <- fread("../lec4-text-basics/train.csv") # fread() is a function in data.table
reviews$label <- reviews$label # coerce 0/1 to category
# text to corpus
twcorpus <- corpus(reviews$text)
# the below commented lien won't work; read the help file
# doc.term <- dfm(twcorpus,  ngrams=1:3, tolower=TRUE, stem=TRUE, remove_punct = TRUE, remove_url=TRUE,  verbose=TRUE, remove=c(stopwords("english"), "the", "t.co", "https", "rt", "amp", "http", "t.c", "can", "u", "<", ">", "br"))
# transform corpus to tokens
tokens <-  tokens(twcorpus, remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE, remove_url = TRUE)
tokens <- tokens_remove(tokens, c(stopwords("english"), "the", "t.co", "https", "rt", "amp", "http", "t.c", "can", "u", "<", ">", "br", " "))
tokens <- tokens_wordstem(tokens)
tokens <- tokens_ngrams(tokens, n = 1, concatenator = ".")
# then generate document-
doc.term <- dfm(tokens,  verbose=TRUE)
print (dim(doc.term))
# and discard too infrequent words;
doc.term <- dfm_trim(doc.term, min_docfreq=50, verbose=TRUE)
print (dim(doc.term))
# and discard too infrequent words;
doc.term <- dfm_trim(doc.term, min_docfreq=100, verbose=TRUE)
print (dim(doc.term))
X <- as.matrix(doc.term)
dim(X)
library(gmodels)
help(fast.pccomp)
??fast.prcomp
library(quanteda)
library(Rtsne)
library(data.table) # this package help you to read large files quicker
reviews <- fread("../lec4-text-basics/train.csv") # fread() is a function in data.table
reviews$label <- reviews$label # coerce 0/1 to category
# text to corpus
twcorpus <- corpus(reviews$text)
# the below commented lien won't work; read the help file
# doc.term <- dfm(twcorpus,  ngrams=1:3, tolower=TRUE, stem=TRUE, remove_punct = TRUE, remove_url=TRUE,  verbose=TRUE, remove=c(stopwords("english"), "the", "t.co", "https", "rt", "amp", "http", "t.c", "can", "u", "<", ">", "br"))
# transform corpus to tokens
tokens <-  tokens(twcorpus, remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE, remove_url = TRUE)
tokens <- tokens_remove(tokens, c(stopwords("english"), "the", "t.co", "https", "rt", "amp", "http", "t.c", "can", "u", "<", ">", "br", " "))
tokens <- tokens_wordstem(tokens)
tokens <- tokens_ngrams(tokens, n = 1, concatenator = ".")
# then generate document-
doc.term <- dfm(tokens,  verbose=TRUE)
print (dim(doc.term))
# and discard too infrequent words;
doc.term <- dfm_trim(doc.term, min_docfreq=200, verbose=TRUE)
print (dim(doc.term))
library(quanteda)
library(Rtsne)
library(data.table) # this package help you to read large files quicker
reviews <- fread("../lec4-text-basics/train.csv") # fread() is a function in data.table
reviews$label <- reviews$label # coerce 0/1 to category
# text to corpus
twcorpus <- corpus(reviews$text)
# the below commented lien won't work; read the help file
# doc.term <- dfm(twcorpus,  ngrams=1:3, tolower=TRUE, stem=TRUE, remove_punct = TRUE, remove_url=TRUE,  verbose=TRUE, remove=c(stopwords("english"), "the", "t.co", "https", "rt", "amp", "http", "t.c", "can", "u", "<", ">", "br"))
# transform corpus to tokens
tokens <-  tokens(twcorpus, remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE, remove_url = TRUE)
tokens <- tokens_remove(tokens, c(stopwords("english"), "the", "t.co", "https", "rt", "amp", "http", "t.c", "can", "u", "<", ">", "br", " "))
tokens <- tokens_wordstem(tokens)
tokens <- tokens_ngrams(tokens, n = 1, concatenator = ".")
# then generate document-
doc.term <- dfm(tokens,  verbose=TRUE)
print (dim(doc.term))
# and discard too infrequent words;
doc.term <- dfm_trim(doc.term, min_docfreq=200, verbose=TRUE)
print (dim(doc.term))
# and discard too infrequent words;
doc.term <- dfm_trim(doc.term, min_docfreq=500, verbose=TRUE)
X <- as.matrix(doc.term)
dim(X)
library(gmodels)
pc <- fast.prcomp(X, retx = TRUE, center = TRUE, scale. = FALSE, tol = NULL)
dim(pc)
X_subset = X[1:1000, ]
dim(X_subset)
pc <- fast.prcomp(X_subset, retx = TRUE, center = TRUE, scale. = FALSE, tol = NULL)
str(pc)
dim(pc)
pc$rotation
dim(pc$rotation)
dim(pc$x)
dim(pc$rotation)
View(pc$rotation)
dim(X_subset = X[1:1000, ])
dim(X_subset)
View(X_subset)
plot(pc$rotation[, 1],  pc$rotation[,2])
pc$rotation[pc$rotation[,1] > 0.5]
pc$rotation[pc$rotation[,1] > 0.5, ]
which(pc$rotation[,1] > 0.5)
which(pc$rotation[,1] > 0.2)
source ("fast_tsne.R")
tsne <- fftRtsne(X_subset, dims = 2, max_iter = 50)
tsne <- Rtsne(X_subset, dims = 2, partial_pca = T, perplexity=30, verbose=TRUE, max_iter = 50)
install.packages("irlba")
tsne <- Rtsne(X_subset, dims = 2, partial_pca = T, perplexity=30, verbose=TRUE, max_iter = 50)
plot(tsne)
str(tsne)
dim(tsne$Y)
embedding <- tsne$Y
plot(embedding[,1], embedding[,2])
head(embedding)
